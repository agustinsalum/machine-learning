{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWnfBGRS0xCv"
      },
      "source": [
        "# **ALGORITMOS (Modelos)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TFGD_eI1N1e"
      },
      "source": [
        "###**k-Nearest Neighbors (k-NN): (SUPERVISADO)**\n",
        "\n",
        "####**Definición:**\n",
        "k-Nearest Neighbors (k-NN) es un algoritmo de aprendizaje supervisado utilizado tanto para clasificación como para regresión. Funciona asignando una etiqueta o valor a un punto de datos basándose en la mayoría de las etiquetas (en clasificación) o en el promedio de los valores (en regresión) de sus k vecinos más cercanos en el espacio de características.\n",
        "####**Explicación:**\n",
        "Para clasificar un punto de datos desconocido con k-NN, se encuentra su k vecinos más cercanos en función de alguna medida de distancia (generalmente la distancia euclidiana) y se determina la etiqueta más común entre esos vecinos. k-NN es un algoritmo simple y versátil, pero su rendimiento puede verse afectado por la elección adecuada de k y la calidad de los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKXTQNou1RwO"
      },
      "source": [
        "#### **Sentido Matemático:**\n",
        "k-NN se basa en la idea de que los puntos de datos similares deberían tener etiquetas similares. Matemáticamente, para clasificar un punto de datos desconocido, se calcula la distancia entre ese punto y todos los demás puntos en el conjunto de entrenamiento. Luego, se seleccionan los k puntos más cercanos (vecinos) y se asigna al punto desconocido la etiqueta que es la más común entre esos k vecinos. La distancia generalmente se calcula usando la distancia euclidiana o alguna otra medida de distancia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zO7uXKQ90tpW",
        "outputId": "eeb41704-1c20-4679-ea34-e6eacd6d6fbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicciones: [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
            " 0 0 0 2 1 1 0 0]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Cargar un conjunto de datos (en este caso, el conjunto de datos Iris)\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Dividir el conjunto de datos en datos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Crear un modelo de k-NN con k=3\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Imprimir las predicciones\n",
        "print(\"Predicciones:\", y_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDpyQ1Gy1bNm"
      },
      "source": [
        "###**k-Means: (NO SUPERVISADO)**\n",
        "\n",
        "####**Definición:**\n",
        "k-Means es un algoritmo de agrupamiento (clustering) que se utiliza para dividir un conjunto de datos en grupos o clústeres basados en la similitud de características. El valor de \"k\" en k-Means representa el número de clústeres que se deben formar.\n",
        "####**Explicación:**\n",
        "El algoritmo k-Means funciona asignando puntos de datos a uno de los k clústeres de manera que la suma de las distancias cuadradas entre los puntos y el centroide (punto central) de su clúster sea mínima. Los centroides se actualizan iterativamente hasta converger a una solución. k-Means es ampliamente utilizado en análisis de datos y segmentación de clientes, entre otras aplicaciones de clustering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJeUJtHI1jZM"
      },
      "source": [
        "####**Sentido Matemático:**\n",
        "k-Means es un algoritmo de agrupamiento que busca minimizar la suma de las distancias cuadradas entre los puntos de datos y los centroides de los clústeres. Matemáticamente, se puede expresar como un problema de optimización donde se minimiza la siguiente función de costo:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McA7bsrq1oQU"
      },
      "source": [
        "![formula.png](data:image/png;base64,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)\n",
        "\n",
        "J = ∑ i=1 to k ∑ j=1 to n ||x_j - c_i||^2\n",
        "\n",
        "Donde J es la función de costo, k es el número de clústeres, n es el número de puntos de datos, x_j es un punto de datos, y c_i es el centroide del clúster i. El objetivo es encontrar los centroides c_i que minimizan esta suma de distancias.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-Eajba7U1pb-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/agustin/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Etiquetas de los clústeres: [2 2 2 2 0 0 2 2 2 1 0 2 2 1 2 2 1 0 2 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 2 2\n",
            " 1 1 1 0 1 2 2 0 0 0 2 0 0 2 0 0 1 2 2 0 0 2 2 1 0 1 0 2 0 1 0 2 1 0 0 2 0\n",
            " 1 0 1 1 2 1 0 2 0 1 2 2 2 0 1 1 1 1 1 0 0 0 1 2 2 2]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "# Generar datos de ejemplo\n",
        "np.random.seed(0)\n",
        "X = np.random.randn(100, 2)\n",
        "\n",
        "# Crear un modelo de k-Means con 3 clústeres\n",
        "kmeans = KMeans(n_clusters=3)\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Etiquetar los puntos de datos con los clústeres asignados\n",
        "labels = kmeans.labels_\n",
        "\n",
        "# Imprimir las etiquetas asignadas a cada punto\n",
        "print(\"Etiquetas de los clústeres:\", labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqrxrDpl1xEC"
      },
      "source": [
        "##**Árbol de Decisión:**\n",
        "\n",
        "###**Definición:**\n",
        "Un árbol de decisión es un modelo de aprendizaje automático que se utiliza tanto para problemas de clasificación como de regresión. Representa una estructura de árbol donde cada nodo interno representa una decisión basada en una característica del conjunto de datos, y cada hoja representa una etiqueta (en clasificación) o un valor (en regresión).\n",
        "###**Explicación:**\n",
        "Los árboles de decisión se construyen dividiendo repetidamente el conjunto de datos en subconjuntos más pequeños en función de la característica que mejor separa las clases o reduce la varianza en el caso de regresión. Se sigue dividiendo hasta que se alcanza un criterio de parada, como la profundidad máxima o un número mínimo de ejemplos por hoja. Los árboles de decisión son fáciles de interpretar y visualizar, lo que los hace populares en aplicaciones donde la explicabilidad del modelo es importante. Además, se pueden usar en conjunto con métodos como Random Forest y Gradient Boosting para mejorar su rendimiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7AOE9Af11dT"
      },
      "source": [
        "### **Sentido Matemático:**\n",
        "Un árbol de decisión es una estructura jerárquica que se construye dividiendo los datos en función de características y criterios de decisión. Matemáticamente, en cada nodo del árbol, se selecciona una característica y un umbral para dividir los datos en dos subconjuntos. La elección de la característica y el umbral se basa en criterios como la ganancia de información o la impureza de Gini en el caso de la clasificación, o la reducción de la varianza en el caso de la regresión. El objetivo es dividir los datos de manera que se minimice la impureza o se maximice la información en cada nodo del árbol."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vJ3rJogX168F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicciones: [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
            " 0 0 0 2 1 1 0 0]\n",
            "Árbol de Decisión:\n",
            " |--- petal width (cm) <= 0.80\n",
            "|   |--- class: 0\n",
            "|--- petal width (cm) >  0.80\n",
            "|   |--- petal width (cm) <= 1.75\n",
            "|   |   |--- petal length (cm) <= 4.95\n",
            "|   |   |   |--- petal width (cm) <= 1.60\n",
            "|   |   |   |   |--- class: 1\n",
            "|   |   |   |--- petal width (cm) >  1.60\n",
            "|   |   |   |   |--- class: 2\n",
            "|   |   |--- petal length (cm) >  4.95\n",
            "|   |   |   |--- petal width (cm) <= 1.55\n",
            "|   |   |   |   |--- class: 2\n",
            "|   |   |   |--- petal width (cm) >  1.55\n",
            "|   |   |   |   |--- petal length (cm) <= 5.45\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |--- petal length (cm) >  5.45\n",
            "|   |   |   |   |   |--- class: 2\n",
            "|   |--- petal width (cm) >  1.75\n",
            "|   |   |--- petal length (cm) <= 4.85\n",
            "|   |   |   |--- sepal width (cm) <= 3.10\n",
            "|   |   |   |   |--- class: 2\n",
            "|   |   |   |--- sepal width (cm) >  3.10\n",
            "|   |   |   |   |--- class: 1\n",
            "|   |   |--- petal length (cm) >  4.85\n",
            "|   |   |   |--- class: 2\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import export_text\n",
        "\n",
        "# Cargar un conjunto de datos (en este caso, el conjunto de datos Iris)\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Dividir el conjunto de datos en datos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Crear un modelo de Árbol de Decisión\n",
        "tree_classifier = DecisionTreeClassifier()\n",
        "tree_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = tree_classifier.predict(X_test)\n",
        "\n",
        "# Imprimir las predicciones\n",
        "print(\"Predicciones:\", y_pred)\n",
        "\n",
        "# Imprimir la estructura del árbol de decisión\n",
        "tree_rules = export_text(tree_classifier, feature_names=iris.feature_names)\n",
        "print(\"Árbol de Decisión:\\n\", tree_rules)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
